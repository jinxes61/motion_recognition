{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_mining/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (19162, 1, 100, 96)\n",
      "Y_train shape: (19162,)\n",
      "X_test shape: (4791, 1, 100, 96)\n",
      "Y_test shape: (4791,)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "\n",
    "####### 修改输入文件\n",
    "file = h5py.File('data/fused_100_96.h5','r')\n",
    "imageData   = file['imageData'][:]\n",
    "imageLabel  = file['imageLabel'][:]  \n",
    "file.close()\n",
    "\n",
    "# 随机打乱数据和标签\n",
    "N = imageData.shape[0]\n",
    "index = np.random.permutation(N)\n",
    "data  = imageData[index,:,:]\n",
    "label = imageLabel[index]\n",
    "\n",
    "# 对数据升维,标签one-hot\n",
    "data  = np.expand_dims(data, axis=1)\n",
    "label = convert_to_one_hot(label,49).T\n",
    "label = np.argmax(label, axis=1)  \n",
    "\n",
    "# 划分数据集\n",
    "N = data.shape[0]\n",
    "num_train = round(N*0.8)\n",
    "X_train = data[0:num_train,:,:,:]\n",
    "Y_train = label[0:num_train]\n",
    "X_test  = data[num_train:N,:,:,:]\n",
    "Y_test  = label[num_train:N]\n",
    "\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_prediction(Dataset):\n",
    "    def __init__(self, data_features, data_target):\n",
    "        self.len = len(data_features)\n",
    "        self.features = torch.from_numpy(data_features)\n",
    "        self.target = torch.from_numpy(data_target)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.target[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "train_set = dataset_prediction(data_features=X_train, data_target=Y_train)\n",
    "test_set = dataset_prediction(data_features=X_test, data_target=Y_test)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set,\n",
    "                            batch_size=64,\n",
    "                            shuffle=True,\n",
    "                            drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ChannelAttentionModule(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):  \n",
    "        super(ChannelAttentionModule, self).__init__()\n",
    "        mid_channel = channel // reduction\n",
    "        # 使用自适应池化缩减map的大小，保持通道不变  \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        self.shared_MLP = nn.Sequential(\n",
    "            nn.Linear(in_features=channel, out_features=mid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=mid_channel, out_features=channel)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # self.act=SiLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        avgout = self.shared_MLP(self.avg_pool(x).view(x.size(0),-1)).unsqueeze(2).unsqueeze(3)\n",
    "        maxout = self.shared_MLP(self.max_pool(x).view(x.size(0),-1)).unsqueeze(2).unsqueeze(3)\n",
    "        return self.sigmoid(avgout + maxout)\n",
    "        \n",
    "# 空间注意力模块\n",
    "class SpatialAttentionModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialAttentionModule, self).__init__()\n",
    "        self.conv2d = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=7, stride=1, padding=3) \n",
    "        # self.act=SiLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # map尺寸不变，缩减通道\n",
    "        avgout = torch.mean(x, dim=1, keepdim=True)\n",
    "        maxout, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        out = torch.cat([avgout, maxout], dim=1)\n",
    "        out = self.sigmoid(self.conv2d(out))\n",
    "        return out\n",
    "\n",
    "# CBAM模块\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, channel): \n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttentionModule(channel)\n",
    "        self.spatial_attention = SpatialAttentionModule()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.channel_attention(x) * x\n",
    "        out = self.spatial_attention(out) * out\n",
    "        return out\n",
    "\n",
    "# Example usage for image classification\n",
    "class CNN_CBAM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_CBAM, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            # 输入[1,200,60]\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=32,\n",
    "                kernel_size=(20,3),\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            # 经过卷积层 输出[32,200,60] 传入池化层\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(10,1))   # 经过池化 输出[32,20,60] 传入下一个卷积\n",
    "        )\n",
    "        ## 第二层卷积\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,    # 同上\n",
    "                out_channels=64,\n",
    "                kernel_size=(3,3),\n",
    "                stride=1,\n",
    "                padding=1\n",
    "            ),\n",
    "            # 经过卷积 输出[64, 40, 30] 传入池化层\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(3,2))  # 经过池化 输出[64,7,30] 传入下一个卷积\n",
    "        )\n",
    "        ## 第三层卷积\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,    # 同上\n",
    "                out_channels=128,\n",
    "                kernel_size=(3,3),\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.cbam = CBAM(channel=128)\n",
    "        self.classifier = nn.Linear(128*50, 49)  # Define your classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: batch_size x channels x height x width (e.g., an image)\n",
    "        x = torch.tensor(x)\n",
    "        x = x.to(torch.float32)\n",
    "        x = x.cuda()\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x) \n",
    "        x = self.cbam(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.classifier(x)  # Classification\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_CBAM(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(20, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(10, 1), stride=(10, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(3, 2), stride=(3, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (cbam): CBAM(\n",
      "    (channel_attention): ChannelAttentionModule(\n",
      "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "      (shared_MLP): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=8, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=8, out_features=128, bias=True)\n",
      "      )\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "    (spatial_attention): SpatialAttentionModule(\n",
      "      (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=6400, out_features=49, bias=True)\n",
      ")\n",
      "进行第0个epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_mining/.local/lib/python3.6/site-packages/ipykernel_launcher.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 3.8921 | test accuracy: 0.04\n",
      "Epoch:  0 | train loss: 1.7664 | test accuracy: 0.44\n",
      "Epoch:  0 | train loss: 1.3026 | test accuracy: 0.64\n",
      "Epoch:  0 | train loss: 0.7281 | test accuracy: 0.74\n",
      "Epoch:  0 | train loss: 0.7793 | test accuracy: 0.80\n",
      "进行第1个epoch\n",
      "Epoch:  1 | train loss: 0.5463 | test accuracy: 0.80\n",
      "Epoch:  1 | train loss: 0.4133 | test accuracy: 0.83\n",
      "Epoch:  1 | train loss: 0.5936 | test accuracy: 0.84\n",
      "Epoch:  1 | train loss: 0.5188 | test accuracy: 0.84\n",
      "Epoch:  1 | train loss: 0.3467 | test accuracy: 0.87\n",
      "进行第2个epoch\n",
      "Epoch:  2 | train loss: 0.3131 | test accuracy: 0.85\n",
      "Epoch:  2 | train loss: 0.4153 | test accuracy: 0.87\n",
      "Epoch:  2 | train loss: 0.2412 | test accuracy: 0.88\n",
      "Epoch:  2 | train loss: 0.4484 | test accuracy: 0.89\n",
      "Epoch:  2 | train loss: 0.4891 | test accuracy: 0.87\n",
      "进行第3个epoch\n",
      "Epoch:  3 | train loss: 0.1614 | test accuracy: 0.89\n",
      "Epoch:  3 | train loss: 0.2204 | test accuracy: 0.89\n",
      "Epoch:  3 | train loss: 0.1562 | test accuracy: 0.90\n",
      "Epoch:  3 | train loss: 0.2915 | test accuracy: 0.88\n",
      "Epoch:  3 | train loss: 0.3033 | test accuracy: 0.90\n",
      "进行第4个epoch\n",
      "Epoch:  4 | train loss: 0.2328 | test accuracy: 0.89\n",
      "Epoch:  4 | train loss: 0.2348 | test accuracy: 0.90\n",
      "Epoch:  4 | train loss: 0.1877 | test accuracy: 0.90\n",
      "Epoch:  4 | train loss: 0.0966 | test accuracy: 0.91\n",
      "Epoch:  4 | train loss: 0.1061 | test accuracy: 0.91\n",
      "进行第5个epoch\n",
      "Epoch:  5 | train loss: 0.2476 | test accuracy: 0.91\n",
      "Epoch:  5 | train loss: 0.1506 | test accuracy: 0.89\n",
      "Epoch:  5 | train loss: 0.1871 | test accuracy: 0.90\n",
      "Epoch:  5 | train loss: 0.1047 | test accuracy: 0.92\n",
      "Epoch:  5 | train loss: 0.2653 | test accuracy: 0.89\n",
      "进行第6个epoch\n",
      "Epoch:  6 | train loss: 0.1692 | test accuracy: 0.90\n",
      "Epoch:  6 | train loss: 0.0435 | test accuracy: 0.92\n",
      "Epoch:  6 | train loss: 0.0440 | test accuracy: 0.90\n",
      "Epoch:  6 | train loss: 0.0463 | test accuracy: 0.91\n",
      "Epoch:  6 | train loss: 0.3947 | test accuracy: 0.92\n",
      "进行第7个epoch\n",
      "Epoch:  7 | train loss: 0.1047 | test accuracy: 0.91\n",
      "Epoch:  7 | train loss: 0.1011 | test accuracy: 0.91\n",
      "Epoch:  7 | train loss: 0.0427 | test accuracy: 0.92\n",
      "Epoch:  7 | train loss: 0.1449 | test accuracy: 0.91\n",
      "Epoch:  7 | train loss: 0.0897 | test accuracy: 0.91\n",
      "进行第8个epoch\n",
      "Epoch:  8 | train loss: 0.1067 | test accuracy: 0.91\n",
      "Epoch:  8 | train loss: 0.0571 | test accuracy: 0.92\n",
      "Epoch:  8 | train loss: 0.1471 | test accuracy: 0.91\n",
      "Epoch:  8 | train loss: 0.0497 | test accuracy: 0.90\n",
      "Epoch:  8 | train loss: 0.1489 | test accuracy: 0.90\n",
      "进行第9个epoch\n",
      "Epoch:  9 | train loss: 0.1134 | test accuracy: 0.93\n",
      "Epoch:  9 | train loss: 0.0413 | test accuracy: 0.92\n",
      "Epoch:  9 | train loss: 0.0538 | test accuracy: 0.92\n",
      "Epoch:  9 | train loss: 0.1614 | test accuracy: 0.90\n",
      "Epoch:  9 | train loss: 0.0245 | test accuracy: 0.92\n",
      "进行第10个epoch\n",
      "Epoch:  10 | train loss: 0.0295 | test accuracy: 0.92\n",
      "Epoch:  10 | train loss: 0.0788 | test accuracy: 0.92\n",
      "Epoch:  10 | train loss: 0.0523 | test accuracy: 0.92\n",
      "Epoch:  10 | train loss: 0.0662 | test accuracy: 0.92\n",
      "Epoch:  10 | train loss: 0.0507 | test accuracy: 0.92\n",
      "进行第11个epoch\n",
      "Epoch:  11 | train loss: 0.2645 | test accuracy: 0.92\n",
      "Epoch:  11 | train loss: 0.1139 | test accuracy: 0.91\n",
      "Epoch:  11 | train loss: 0.0188 | test accuracy: 0.92\n",
      "Epoch:  11 | train loss: 0.1740 | test accuracy: 0.91\n",
      "Epoch:  11 | train loss: 0.0150 | test accuracy: 0.92\n",
      "进行第12个epoch\n",
      "Epoch:  12 | train loss: 0.1064 | test accuracy: 0.92\n",
      "Epoch:  12 | train loss: 0.0064 | test accuracy: 0.93\n",
      "Epoch:  12 | train loss: 0.0088 | test accuracy: 0.93\n",
      "Epoch:  12 | train loss: 0.0617 | test accuracy: 0.92\n",
      "Epoch:  12 | train loss: 0.0513 | test accuracy: 0.92\n",
      "进行第13个epoch\n",
      "Epoch:  13 | train loss: 0.0284 | test accuracy: 0.91\n",
      "Epoch:  13 | train loss: 0.0177 | test accuracy: 0.92\n",
      "Epoch:  13 | train loss: 0.1273 | test accuracy: 0.93\n",
      "Epoch:  13 | train loss: 0.0597 | test accuracy: 0.91\n",
      "Epoch:  13 | train loss: 0.0408 | test accuracy: 0.92\n",
      "进行第14个epoch\n",
      "Epoch:  14 | train loss: 0.1299 | test accuracy: 0.92\n",
      "Epoch:  14 | train loss: 0.1601 | test accuracy: 0.89\n",
      "Epoch:  14 | train loss: 0.0205 | test accuracy: 0.92\n",
      "Epoch:  14 | train loss: 0.0459 | test accuracy: 0.91\n",
      "Epoch:  14 | train loss: 0.0083 | test accuracy: 0.93\n",
      "进行第15个epoch\n",
      "Epoch:  15 | train loss: 0.0917 | test accuracy: 0.93\n",
      "Epoch:  15 | train loss: 0.0077 | test accuracy: 0.92\n",
      "Epoch:  15 | train loss: 0.0658 | test accuracy: 0.91\n",
      "Epoch:  15 | train loss: 0.0128 | test accuracy: 0.92\n",
      "Epoch:  15 | train loss: 0.0076 | test accuracy: 0.92\n",
      "进行第16个epoch\n",
      "Epoch:  16 | train loss: 0.0757 | test accuracy: 0.92\n",
      "Epoch:  16 | train loss: 0.0031 | test accuracy: 0.92\n",
      "Epoch:  16 | train loss: 0.0019 | test accuracy: 0.93\n",
      "Epoch:  16 | train loss: 0.0178 | test accuracy: 0.92\n",
      "Epoch:  16 | train loss: 0.0090 | test accuracy: 0.90\n",
      "进行第17个epoch\n",
      "Epoch:  17 | train loss: 0.0401 | test accuracy: 0.92\n",
      "Epoch:  17 | train loss: 0.0237 | test accuracy: 0.92\n",
      "Epoch:  17 | train loss: 0.1447 | test accuracy: 0.92\n",
      "Epoch:  17 | train loss: 0.0098 | test accuracy: 0.92\n",
      "Epoch:  17 | train loss: 0.0037 | test accuracy: 0.91\n",
      "进行第18个epoch\n",
      "Epoch:  18 | train loss: 0.0063 | test accuracy: 0.92\n",
      "Epoch:  18 | train loss: 0.0595 | test accuracy: 0.92\n",
      "Epoch:  18 | train loss: 0.0507 | test accuracy: 0.91\n",
      "Epoch:  18 | train loss: 0.0058 | test accuracy: 0.92\n",
      "Epoch:  18 | train loss: 0.0024 | test accuracy: 0.93\n",
      "进行第19个epoch\n",
      "Epoch:  19 | train loss: 0.0021 | test accuracy: 0.92\n",
      "Epoch:  19 | train loss: 0.0139 | test accuracy: 0.92\n",
      "Epoch:  19 | train loss: 0.0119 | test accuracy: 0.91\n",
      "Epoch:  19 | train loss: 0.0059 | test accuracy: 0.92\n",
      "Epoch:  19 | train loss: 0.0173 | test accuracy: 0.92\n",
      "进行第20个epoch\n",
      "Epoch:  20 | train loss: 0.0220 | test accuracy: 0.91\n",
      "Epoch:  20 | train loss: 0.0187 | test accuracy: 0.92\n",
      "Epoch:  20 | train loss: 0.0105 | test accuracy: 0.91\n",
      "Epoch:  20 | train loss: 0.0359 | test accuracy: 0.91\n",
      "Epoch:  20 | train loss: 0.0009 | test accuracy: 0.92\n",
      "进行第21个epoch\n",
      "Epoch:  21 | train loss: 0.0011 | test accuracy: 0.93\n",
      "Epoch:  21 | train loss: 0.0221 | test accuracy: 0.93\n",
      "Epoch:  21 | train loss: 0.0025 | test accuracy: 0.93\n",
      "Epoch:  21 | train loss: 0.0166 | test accuracy: 0.93\n",
      "Epoch:  21 | train loss: 0.0101 | test accuracy: 0.93\n",
      "进行第22个epoch\n",
      "Epoch:  22 | train loss: 0.0073 | test accuracy: 0.92\n",
      "Epoch:  22 | train loss: 0.0037 | test accuracy: 0.93\n",
      "Epoch:  22 | train loss: 0.0048 | test accuracy: 0.93\n",
      "Epoch:  22 | train loss: 0.0806 | test accuracy: 0.91\n",
      "Epoch:  22 | train loss: 0.0213 | test accuracy: 0.91\n",
      "进行第23个epoch\n",
      "Epoch:  23 | train loss: 0.0185 | test accuracy: 0.92\n",
      "Epoch:  23 | train loss: 0.0172 | test accuracy: 0.92\n",
      "Epoch:  23 | train loss: 0.0092 | test accuracy: 0.92\n",
      "Epoch:  23 | train loss: 0.0294 | test accuracy: 0.92\n",
      "Epoch:  23 | train loss: 0.0023 | test accuracy: 0.90\n",
      "进行第24个epoch\n",
      "Epoch:  24 | train loss: 0.0242 | test accuracy: 0.91\n",
      "Epoch:  24 | train loss: 0.0021 | test accuracy: 0.92\n",
      "Epoch:  24 | train loss: 0.0172 | test accuracy: 0.92\n",
      "Epoch:  24 | train loss: 0.0087 | test accuracy: 0.91\n",
      "Epoch:  24 | train loss: 0.0289 | test accuracy: 0.91\n",
      "进行第25个epoch\n",
      "Epoch:  25 | train loss: 0.0111 | test accuracy: 0.92\n",
      "Epoch:  25 | train loss: 0.0335 | test accuracy: 0.93\n",
      "Epoch:  25 | train loss: 0.0017 | test accuracy: 0.93\n",
      "Epoch:  25 | train loss: 0.0008 | test accuracy: 0.93\n",
      "Epoch:  25 | train loss: 0.0368 | test accuracy: 0.93\n",
      "进行第26个epoch\n",
      "Epoch:  26 | train loss: 0.0015 | test accuracy: 0.93\n",
      "Epoch:  26 | train loss: 0.0013 | test accuracy: 0.93\n",
      "Epoch:  26 | train loss: 0.0276 | test accuracy: 0.91\n",
      "Epoch:  26 | train loss: 0.0099 | test accuracy: 0.92\n",
      "Epoch:  26 | train loss: 0.1043 | test accuracy: 0.90\n",
      "进行第27个epoch\n",
      "Epoch:  27 | train loss: 0.0446 | test accuracy: 0.90\n",
      "Epoch:  27 | train loss: 0.0069 | test accuracy: 0.92\n",
      "Epoch:  27 | train loss: 0.0449 | test accuracy: 0.91\n",
      "Epoch:  27 | train loss: 0.0032 | test accuracy: 0.92\n",
      "Epoch:  27 | train loss: 0.0396 | test accuracy: 0.92\n",
      "进行第28个epoch\n",
      "Epoch:  28 | train loss: 0.0041 | test accuracy: 0.92\n",
      "Epoch:  28 | train loss: 0.0009 | test accuracy: 0.93\n",
      "Epoch:  28 | train loss: 0.2082 | test accuracy: 0.91\n",
      "Epoch:  28 | train loss: 0.0258 | test accuracy: 0.91\n",
      "Epoch:  28 | train loss: 0.0067 | test accuracy: 0.92\n",
      "进行第29个epoch\n",
      "Epoch:  29 | train loss: 0.0013 | test accuracy: 0.92\n",
      "Epoch:  29 | train loss: 0.0005 | test accuracy: 0.92\n",
      "Epoch:  29 | train loss: 0.0068 | test accuracy: 0.92\n",
      "Epoch:  29 | train loss: 0.0110 | test accuracy: 0.91\n",
      "Epoch:  29 | train loss: 0.0006 | test accuracy: 0.93\n",
      "进行第30个epoch\n",
      "Epoch:  30 | train loss: 0.0443 | test accuracy: 0.92\n",
      "Epoch:  30 | train loss: 0.0054 | test accuracy: 0.93\n",
      "Epoch:  30 | train loss: 0.0055 | test accuracy: 0.92\n",
      "Epoch:  30 | train loss: 0.0383 | test accuracy: 0.92\n",
      "Epoch:  30 | train loss: 0.0270 | test accuracy: 0.92\n",
      "进行第31个epoch\n",
      "Epoch:  31 | train loss: 0.0214 | test accuracy: 0.92\n",
      "Epoch:  31 | train loss: 0.1341 | test accuracy: 0.91\n",
      "Epoch:  31 | train loss: 0.0052 | test accuracy: 0.93\n",
      "Epoch:  31 | train loss: 0.0053 | test accuracy: 0.92\n",
      "Epoch:  31 | train loss: 0.0052 | test accuracy: 0.92\n",
      "进行第32个epoch\n",
      "Epoch:  32 | train loss: 0.0001 | test accuracy: 0.91\n",
      "Epoch:  32 | train loss: 0.0083 | test accuracy: 0.92\n",
      "Epoch:  32 | train loss: 0.0093 | test accuracy: 0.92\n",
      "Epoch:  32 | train loss: 0.0018 | test accuracy: 0.92\n",
      "Epoch:  32 | train loss: 0.0757 | test accuracy: 0.92\n",
      "进行第33个epoch\n",
      "Epoch:  33 | train loss: 0.0010 | test accuracy: 0.90\n",
      "Epoch:  33 | train loss: 0.0307 | test accuracy: 0.92\n",
      "Epoch:  33 | train loss: 0.0056 | test accuracy: 0.92\n",
      "Epoch:  33 | train loss: 0.0002 | test accuracy: 0.92\n",
      "Epoch:  33 | train loss: 0.0061 | test accuracy: 0.92\n",
      "进行第34个epoch\n",
      "Epoch:  34 | train loss: 0.0018 | test accuracy: 0.92\n",
      "Epoch:  34 | train loss: 0.0036 | test accuracy: 0.93\n",
      "Epoch:  34 | train loss: 0.0172 | test accuracy: 0.92\n",
      "Epoch:  34 | train loss: 0.0172 | test accuracy: 0.91\n",
      "Epoch:  34 | train loss: 0.0116 | test accuracy: 0.91\n",
      "进行第35个epoch\n",
      "Epoch:  35 | train loss: 0.0625 | test accuracy: 0.89\n",
      "Epoch:  35 | train loss: 0.1077 | test accuracy: 0.91\n",
      "Epoch:  35 | train loss: 0.0354 | test accuracy: 0.92\n",
      "Epoch:  35 | train loss: 0.0309 | test accuracy: 0.91\n",
      "Epoch:  35 | train loss: 0.0053 | test accuracy: 0.91\n",
      "进行第36个epoch\n",
      "Epoch:  36 | train loss: 0.0879 | test accuracy: 0.87\n",
      "Epoch:  36 | train loss: 0.0019 | test accuracy: 0.91\n",
      "Epoch:  36 | train loss: 0.0720 | test accuracy: 0.92\n",
      "Epoch:  36 | train loss: 0.0027 | test accuracy: 0.92\n",
      "Epoch:  36 | train loss: 0.0899 | test accuracy: 0.92\n",
      "进行第37个epoch\n",
      "Epoch:  37 | train loss: 0.0563 | test accuracy: 0.92\n",
      "Epoch:  37 | train loss: 0.0004 | test accuracy: 0.93\n",
      "Epoch:  37 | train loss: 0.0005 | test accuracy: 0.93\n",
      "Epoch:  37 | train loss: 0.0134 | test accuracy: 0.94\n",
      "Epoch:  37 | train loss: 0.0002 | test accuracy: 0.93\n",
      "进行第38个epoch\n",
      "Epoch:  38 | train loss: 0.0009 | test accuracy: 0.93\n",
      "Epoch:  38 | train loss: 0.0007 | test accuracy: 0.93\n",
      "Epoch:  38 | train loss: 0.0002 | test accuracy: 0.93\n",
      "Epoch:  38 | train loss: 0.0364 | test accuracy: 0.93\n",
      "Epoch:  38 | train loss: 0.0082 | test accuracy: 0.91\n",
      "进行第39个epoch\n",
      "Epoch:  39 | train loss: 0.0015 | test accuracy: 0.93\n",
      "Epoch:  39 | train loss: 0.0004 | test accuracy: 0.93\n",
      "Epoch:  39 | train loss: 0.0002 | test accuracy: 0.93\n",
      "Epoch:  39 | train loss: 0.0005 | test accuracy: 0.93\n",
      "Epoch:  39 | train loss: 0.0353 | test accuracy: 0.92\n",
      "进行第40个epoch\n",
      "Epoch:  40 | train loss: 0.0312 | test accuracy: 0.91\n",
      "Epoch:  40 | train loss: 0.0002 | test accuracy: 0.92\n",
      "Epoch:  40 | train loss: 0.0005 | test accuracy: 0.92\n",
      "Epoch:  40 | train loss: 0.0515 | test accuracy: 0.93\n",
      "Epoch:  40 | train loss: 0.0155 | test accuracy: 0.92\n",
      "进行第41个epoch\n",
      "Epoch:  41 | train loss: 0.0062 | test accuracy: 0.89\n",
      "Epoch:  41 | train loss: 0.0283 | test accuracy: 0.90\n",
      "Epoch:  41 | train loss: 0.0032 | test accuracy: 0.92\n",
      "Epoch:  41 | train loss: 0.0013 | test accuracy: 0.92\n",
      "Epoch:  41 | train loss: 0.0381 | test accuracy: 0.91\n",
      "进行第42个epoch\n",
      "Epoch:  42 | train loss: 0.0067 | test accuracy: 0.91\n",
      "Epoch:  42 | train loss: 0.0304 | test accuracy: 0.91\n",
      "Epoch:  42 | train loss: 0.0007 | test accuracy: 0.91\n",
      "Epoch:  42 | train loss: 0.0117 | test accuracy: 0.91\n",
      "Epoch:  42 | train loss: 0.0051 | test accuracy: 0.92\n",
      "进行第43个epoch\n",
      "Epoch:  43 | train loss: 0.0011 | test accuracy: 0.92\n",
      "Epoch:  43 | train loss: 0.0087 | test accuracy: 0.91\n",
      "Epoch:  43 | train loss: 0.0002 | test accuracy: 0.92\n",
      "Epoch:  43 | train loss: 0.0077 | test accuracy: 0.92\n",
      "Epoch:  43 | train loss: 0.1074 | test accuracy: 0.92\n",
      "进行第44个epoch\n",
      "Epoch:  44 | train loss: 0.0008 | test accuracy: 0.92\n",
      "Epoch:  44 | train loss: 0.0442 | test accuracy: 0.92\n",
      "Epoch:  44 | train loss: 0.0031 | test accuracy: 0.91\n",
      "Epoch:  44 | train loss: 0.0432 | test accuracy: 0.92\n",
      "Epoch:  44 | train loss: 0.0297 | test accuracy: 0.92\n",
      "进行第45个epoch\n",
      "Epoch:  45 | train loss: 0.1103 | test accuracy: 0.92\n",
      "Epoch:  45 | train loss: 0.0014 | test accuracy: 0.92\n",
      "Epoch:  45 | train loss: 0.0005 | test accuracy: 0.93\n",
      "Epoch:  45 | train loss: 0.0029 | test accuracy: 0.92\n",
      "Epoch:  45 | train loss: 0.0195 | test accuracy: 0.92\n",
      "进行第46个epoch\n",
      "Epoch:  46 | train loss: 0.0173 | test accuracy: 0.92\n",
      "Epoch:  46 | train loss: 0.0061 | test accuracy: 0.90\n",
      "Epoch:  46 | train loss: 0.0027 | test accuracy: 0.92\n",
      "Epoch:  46 | train loss: 0.0063 | test accuracy: 0.90\n",
      "Epoch:  46 | train loss: 0.0387 | test accuracy: 0.90\n",
      "进行第47个epoch\n",
      "Epoch:  47 | train loss: 0.0050 | test accuracy: 0.92\n",
      "Epoch:  47 | train loss: 0.0084 | test accuracy: 0.92\n",
      "Epoch:  47 | train loss: 0.0539 | test accuracy: 0.91\n",
      "Epoch:  47 | train loss: 0.0324 | test accuracy: 0.92\n",
      "Epoch:  47 | train loss: 0.0016 | test accuracy: 0.91\n",
      "进行第48个epoch\n",
      "Epoch:  48 | train loss: 0.0043 | test accuracy: 0.91\n",
      "Epoch:  48 | train loss: 0.0001 | test accuracy: 0.91\n",
      "Epoch:  48 | train loss: 0.0009 | test accuracy: 0.91\n",
      "Epoch:  48 | train loss: 0.0087 | test accuracy: 0.92\n",
      "Epoch:  48 | train loss: 0.0106 | test accuracy: 0.91\n",
      "进行第49个epoch\n",
      "Epoch:  49 | train loss: 0.0002 | test accuracy: 0.91\n",
      "Epoch:  49 | train loss: 0.0002 | test accuracy: 0.93\n",
      "Epoch:  49 | train loss: 0.0006 | test accuracy: 0.91\n",
      "Epoch:  49 | train loss: 0.0005 | test accuracy: 0.92\n",
      "Epoch:  49 | train loss: 0.0001 | test accuracy: 0.92\n",
      "进行第50个epoch\n",
      "Epoch:  50 | train loss: 0.0074 | test accuracy: 0.92\n",
      "Epoch:  50 | train loss: 0.0001 | test accuracy: 0.92\n",
      "Epoch:  50 | train loss: 0.0017 | test accuracy: 0.92\n",
      "Epoch:  50 | train loss: 0.0007 | test accuracy: 0.93\n",
      "Epoch:  50 | train loss: 0.0003 | test accuracy: 0.93\n",
      "进行第51个epoch\n",
      "Epoch:  51 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  51 | train loss: 0.0003 | test accuracy: 0.93\n",
      "Epoch:  51 | train loss: 0.0001 | test accuracy: 0.93\n",
      "Epoch:  51 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  51 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第52个epoch\n",
      "Epoch:  52 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  52 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  52 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  52 | train loss: 0.0001 | test accuracy: 0.93\n",
      "Epoch:  52 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第53个epoch\n",
      "Epoch:  53 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  53 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  53 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  53 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  53 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第54个epoch\n",
      "Epoch:  54 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  54 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  54 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  54 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  54 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第55个epoch\n",
      "Epoch:  55 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  55 | train loss: 0.0001 | test accuracy: 0.93\n",
      "Epoch:  55 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  55 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  55 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第56个epoch\n",
      "Epoch:  56 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  56 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  56 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  56 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  56 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第57个epoch\n",
      "Epoch:  57 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  57 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  57 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  57 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  57 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第58个epoch\n",
      "Epoch:  58 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  58 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  58 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  58 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  58 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第59个epoch\n",
      "Epoch:  59 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  59 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  59 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  59 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  59 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第60个epoch\n",
      "Epoch:  60 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  60 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  60 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  60 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  60 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第61个epoch\n",
      "Epoch:  61 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  61 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  61 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  61 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  61 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第62个epoch\n",
      "Epoch:  62 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  62 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  62 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  62 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  62 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第63个epoch\n",
      "Epoch:  63 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  63 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  63 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  63 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  63 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第64个epoch\n",
      "Epoch:  64 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  64 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  64 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  64 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  64 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第65个epoch\n",
      "Epoch:  65 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  65 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  65 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  65 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  65 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第66个epoch\n",
      "Epoch:  66 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  66 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  66 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  66 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  66 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第67个epoch\n",
      "Epoch:  67 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  67 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  67 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  67 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  67 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第68个epoch\n",
      "Epoch:  68 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  68 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  68 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  68 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  68 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第69个epoch\n",
      "Epoch:  69 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  69 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  69 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  69 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  69 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第70个epoch\n",
      "Epoch:  70 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  70 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  70 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  70 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  70 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第71个epoch\n",
      "Epoch:  71 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  71 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  71 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  71 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  71 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第72个epoch\n",
      "Epoch:  72 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  72 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  72 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  72 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  72 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第73个epoch\n",
      "Epoch:  73 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  73 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  73 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  73 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  73 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第74个epoch\n",
      "Epoch:  74 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  74 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  74 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  74 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  74 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第75个epoch\n",
      "Epoch:  75 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  75 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  75 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  75 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  75 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第76个epoch\n",
      "Epoch:  76 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  76 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  76 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  76 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  76 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第77个epoch\n",
      "Epoch:  77 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  77 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  77 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  77 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  77 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第78个epoch\n",
      "Epoch:  78 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  78 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  78 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  78 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  78 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第79个epoch\n",
      "Epoch:  79 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  79 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  79 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  79 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  79 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第80个epoch\n",
      "Epoch:  80 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  80 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  80 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  80 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  80 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第81个epoch\n",
      "Epoch:  81 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  81 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  81 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  81 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  81 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第82个epoch\n",
      "Epoch:  82 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  82 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  82 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  82 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  82 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第83个epoch\n",
      "Epoch:  83 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  83 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  83 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  83 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  83 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第84个epoch\n",
      "Epoch:  84 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  84 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  84 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  84 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  84 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第85个epoch\n",
      "Epoch:  85 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  85 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  85 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  85 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  85 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第86个epoch\n",
      "Epoch:  86 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  86 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  86 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  86 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  86 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第87个epoch\n",
      "Epoch:  87 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  87 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  87 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  87 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  87 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第88个epoch\n",
      "Epoch:  88 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  88 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  88 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  88 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  88 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第89个epoch\n",
      "Epoch:  89 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  89 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  89 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  89 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  89 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第90个epoch\n",
      "Epoch:  90 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  90 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  90 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  90 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  90 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第91个epoch\n",
      "Epoch:  91 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  91 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  91 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  91 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  91 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第92个epoch\n",
      "Epoch:  92 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  92 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  92 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  92 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  92 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第93个epoch\n",
      "Epoch:  93 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  93 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  93 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  93 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  93 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第94个epoch\n",
      "Epoch:  94 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  94 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  94 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  94 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  94 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第95个epoch\n",
      "Epoch:  95 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  95 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  95 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  95 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  95 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第96个epoch\n",
      "Epoch:  96 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  96 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  96 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  96 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  96 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第97个epoch\n",
      "Epoch:  97 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  97 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  97 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  97 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  97 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第98个epoch\n",
      "Epoch:  98 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  98 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  98 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  98 | train loss: 0.0000 | test accuracy: 0.94\n",
      "Epoch:  98 | train loss: 0.0000 | test accuracy: 0.93\n",
      "进行第99个epoch\n",
      "Epoch:  99 | train loss: 0.0000 | test accuracy: 0.94\n",
      "Epoch:  99 | train loss: 0.0000 | test accuracy: 0.93\n",
      "Epoch:  99 | train loss: 0.0000 | test accuracy: 0.94\n",
      "Epoch:  99 | train loss: 0.0000 | test accuracy: 0.94\n",
      "Epoch:  99 | train loss: 0.0000 | test accuracy: 0.94\n",
      "[10 44 15 12  4  8 24 34 32 15]\n",
      "[[[[-3.07589695e-02  1.11115547e-02  3.61391574e-01 ...  8.27624440e-01\n",
      "     4.43919718e-01  3.24334055e-02]\n",
      "   [-1.44510055e-02  6.13021851e-03  3.40398133e-01 ...  8.27624440e-01\n",
      "     4.42775607e-01  3.24334055e-02]\n",
      "   [ 7.59478956e-02 -4.59939241e-03  2.71170437e-01 ...  8.27624440e-01\n",
      "     4.41631496e-01  3.24334055e-02]\n",
      "   ...\n",
      "   [-9.53797877e-01 -1.04998887e+00 -1.19885349e+00 ...  8.20552051e-01\n",
      "     4.32477266e-01  3.24334055e-02]\n",
      "   [-1.20742440e+00 -1.15712929e+00 -1.38862991e+00 ...  8.19373071e-01\n",
      "     4.32477266e-01  3.24334055e-02]\n",
      "   [-1.40308583e+00 -1.30929172e+00 -1.53966391e+00 ...  8.18194151e-01\n",
      "     4.32477266e-01  3.24334055e-02]]]\n",
      "\n",
      "\n",
      " [[[-3.95753831e-01 -7.51446009e-01 -4.17078584e-01 ...  4.45643932e-01\n",
      "     8.53345037e-01 -1.62167028e-02]\n",
      "   [ 8.64560381e-02 -4.48131263e-01 -4.43685316e-02 ...  4.45643932e-01\n",
      "     8.54489148e-01 -1.62167028e-02]\n",
      "   [ 5.98727524e-01 -6.55046403e-02  2.98542976e-01 ...  4.45643932e-01\n",
      "     8.55633259e-01 -1.62167028e-02]\n",
      "   ...\n",
      "   [ 3.37188870e-01  3.47929895e-01  3.08474213e-01 ...  4.45643932e-01\n",
      "     8.80400121e-01 -9.18594096e-03]\n",
      "   [ 5.47335267e-01  5.88832676e-01  5.29358089e-01 ...  4.45643932e-01\n",
      "     8.80400121e-01 -7.98470341e-03]\n",
      "   [ 9.41057444e-01  9.81580853e-01  9.19372797e-01 ...  4.45643932e-01\n",
      "     8.80400121e-01 -6.78346585e-03]]]\n",
      "\n",
      "\n",
      " [[[-8.38149041e-02 -7.84230888e-01 -1.41280130e-01 ...  8.11708570e-01\n",
      "     4.94259745e-01 -1.62167028e-02]\n",
      "   [-2.37139001e-01 -1.02960563e+00 -1.17474377e-01 ...  8.11708570e-01\n",
      "     4.94259745e-01 -1.62167028e-02]\n",
      "   [-7.76494861e-01 -1.05656374e+00 -1.33988053e-01 ...  8.11708570e-01\n",
      "     4.94259745e-01 -1.62167028e-02]\n",
      "   ...\n",
      "   [-4.71392244e-01 -2.88434684e-01 -1.55784748e-02 ...  8.12296748e-01\n",
      "     5.40596604e-01  1.62167028e-02]\n",
      "   [-2.21362278e-01 -3.36909592e-01  6.54568151e-02 ...  8.13475668e-01\n",
      "     5.40596604e-01  1.62167028e-02]\n",
      "   [ 5.33484556e-02 -1.63715973e-01  2.28298455e-01 ...  8.14654648e-01\n",
      "     5.40596604e-01  1.62167028e-02]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-2.71527708e-01 -2.18308359e-01 -1.46327600e-01 ...  5.72970808e-01\n",
      "     8.03172052e-01  6.48668110e-02]\n",
      "   [-2.26934463e-01 -1.56608075e-01 -1.09401330e-01 ...  5.72970808e-01\n",
      "     8.03172052e-01  6.48668110e-02]\n",
      "   [-1.60803869e-01 -9.14626271e-02 -6.78959563e-02 ...  5.72970808e-01\n",
      "     8.03172052e-01  6.48668110e-02]\n",
      "   ...\n",
      "   [-2.49929484e-02  1.16940876e-02 -2.89042220e-02 ...  5.57054937e-01\n",
      "     7.37891853e-01  8.10835212e-02]\n",
      "   [ 1.22663423e-01  8.24068189e-02  6.63318951e-03 ...  5.57054937e-01\n",
      "     7.39035964e-01  8.10835212e-02]\n",
      "   [ 2.37835944e-01  1.71383247e-01  8.25339407e-02 ...  5.57054937e-01\n",
      "     7.40180075e-01  8.10835212e-02]]]\n",
      "\n",
      "\n",
      " [[[ 1.06909895e+00  7.25513935e-01  4.98450249e-01 ...  7.59174764e-01\n",
      "     5.86933434e-01  2.75566690e-02]\n",
      "   [ 3.31743389e-01  1.88818276e-02  1.12495661e-01 ...  7.60353684e-01\n",
      "     5.86933434e-01  2.87579056e-02]\n",
      "   [-5.70560873e-01 -4.00447488e-01 -9.45336074e-02 ...  7.61532664e-01\n",
      "     5.86933434e-01  2.99591422e-02]\n",
      "   ...\n",
      "   [-1.84070319e-03 -5.98728657e-03 -1.16029251e-02 ...  7.48045146e-01\n",
      "     6.19609177e-01  3.24334055e-02]\n",
      "   [ 6.49629757e-02  5.77869900e-02  4.41700295e-02 ...  7.48045146e-01\n",
      "     6.18465066e-01  3.24334055e-02]\n",
      "   [ 1.47724703e-01  1.37392849e-01  1.20431922e-01 ...  7.48045146e-01\n",
      "     6.17824614e-01  3.29622366e-02]]]\n",
      "\n",
      "\n",
      " [[[ 3.54444361e+00  2.58567524e+00  2.64439583e+00 ...  7.79876888e-01\n",
      "     5.56042194e-01  5.46549559e-02]\n",
      "   [ 1.96216917e+00  9.35639262e-01  1.70503581e+00 ...  7.79876888e-01\n",
      "     5.56042194e-01  5.58561906e-02]\n",
      "   [ 4.27713841e-02 -1.08099341e-01  1.01934123e+00 ...  7.79876888e-01\n",
      "     5.56042194e-01  5.70574291e-02]\n",
      "   ...\n",
      "   [ 1.93545491e-01 -1.29991211e-02 -3.96096297e-02 ...  7.95792758e-01\n",
      "     5.09705365e-01  8.10835212e-02]\n",
      "   [-2.91194499e-01 -1.88347518e-01 -2.05082119e-01 ...  7.95792758e-01\n",
      "     5.09705365e-01  8.10835212e-02]\n",
      "   [-6.72749043e-01 -4.70491827e-01 -4.62453663e-01 ...  7.95792758e-01\n",
      "     5.09705365e-01  8.10835212e-02]]]]\n"
     ]
    }
   ],
   "source": [
    "# cnn 实例化\n",
    "cnn_cbam = CNN_CBAM()\n",
    "print(cnn_cbam)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cnn_cbam = cnn_cbam.cuda()\n",
    "\n",
    "epoches = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "optimizer = torch.optim.Adam(cnn_cbam.parameters(), lr=learning_rate)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "if torch.cuda.is_available():\n",
    "    loss_function = loss_function.cuda()\n",
    "\n",
    "# 开始训练\n",
    "for epoch in range(epoches):\n",
    "    print(\"进行第{}个epoch\".format(epoch))\n",
    "    for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        batch_x = batch_x.cuda()\n",
    "        batch_y = batch_y.cuda()\n",
    "        \n",
    "        output = cnn_cbam(batch_x)  # batch_x=[64,1,200,60]\n",
    "\n",
    "        loss = loss_function(output, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 为了实时显示准确率\n",
    "        if step % 64 == 0:\n",
    "            test_output = cnn_cbam(X_test).cpu()\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "            accuracy = float(np.sum(pred_y == Y_test)) / float(Y_test.shape[0])\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.cpu().data.numpy(), '| test accuracy: %.2f' % accuracy)\n",
    "\n",
    "\n",
    "test_output = cnn_cbam(X_test[:10]).cpu()\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "print(pred_y)\n",
    "print(X_test[:10])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
