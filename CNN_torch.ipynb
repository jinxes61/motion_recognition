{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%matplotlib inline\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "\n",
    "####### 修改输入文件\n",
    "filename = 'fused_200_96.h5'\n",
    "file = h5py.File(os.path.join('data/',filename),'r')\n",
    "imageData   = file['imageData'][:]\n",
    "imageLabel  = file['imageLabel'][:]  \n",
    "file.close()\n",
    "\n",
    "# 随机打乱数据和标签\n",
    "N = imageData.shape[0]\n",
    "index = np.random.permutation(N)\n",
    "data  = imageData[index,:,:]\n",
    "label = imageLabel[index]\n",
    "\n",
    "# 对数据升维,标签one-hot\n",
    "data  = np.expand_dims(data, axis=1)\n",
    "label = convert_to_one_hot(label,49).T\n",
    "label = np.argmax(label, axis=1)  \n",
    "\n",
    "# 划分数据集\n",
    "N = data.shape[0]\n",
    "num_train = round(N*0.8)\n",
    "X_train = data[0:num_train,:,:,:]\n",
    "Y_train = label[0:num_train]\n",
    "X_test  = data[num_train:N,:,:,:]\n",
    "Y_test  = label[num_train:N]\n",
    "\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_prediction(Dataset):\n",
    "    def __init__(self, data_features, data_target):\n",
    "        self.len = len(data_features)\n",
    "        self.features = torch.from_numpy(data_features)\n",
    "        self.target = torch.from_numpy(data_target)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.target[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "train_set = dataset_prediction(data_features=X_train, data_target=Y_train)\n",
    "test_set = dataset_prediction(data_features=X_test, data_target=Y_test)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set,\n",
    "                            batch_size=64,\n",
    "                            shuffle=True,\n",
    "                            drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()   # 继承__init__功能\n",
    "        ## 第一层卷积\n",
    "        self.conv1 = nn.Sequential(\n",
    "            # 输入[1,200,60]\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,    # 输入图片的高度\n",
    "                out_channels=32,  # 输出图片的高度\n",
    "                kernel_size=(20,3),    # 20x3的卷积核，相当于过滤器\n",
    "                stride=1,         # 卷积核在图上滑动，每隔一个扫一次\n",
    "                padding=2,        # 给图外边补上0\n",
    "            ),\n",
    "            # 经过卷积层 输出[32,200,60] 传入池化层\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(10,1))   # 经过池化 输出[32,20,60] 传入下一个卷积\n",
    "        )\n",
    "        ## 第二层卷积\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,    # 同上\n",
    "                out_channels=64,\n",
    "                kernel_size=(3,3),\n",
    "                stride=1,\n",
    "                padding=1\n",
    "            ),\n",
    "            # 经过卷积 输出[64, 40, 30] 传入池化层\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(3,2))  # 经过池化 输出[64,7,30] 传入下一个卷积\n",
    "        )\n",
    "        ## 第三层卷积\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,    # 同上\n",
    "                out_channels=128,\n",
    "                kernel_size=(3,3),\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            # 经过卷积 输出[128, 6, 30] 传入池化层\n",
    "            ####### 这几个的 size 计算有点迷，得看加了 padding 之后对池化的影响\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)  # 经过池化 输出[128,4,17] 传入下一个卷积\n",
    "        )\n",
    "\n",
    "        ## 输出层 \n",
    "        ######### in_features 只要对齐就行了，看编译器要多少就改成多少\n",
    "        self.output = nn.Linear(in_features=128*2*25, out_features=49)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tensor(x)\n",
    "        x = x.to(torch.float32)\n",
    "        x = x.cuda()\n",
    "        x = self.conv1(x)\n",
    "        # print(\"After conv1:\", x.shape)\n",
    "        x = self.conv2(x)           #\n",
    "        # print(\"After conv2:\", x.shape)\n",
    "        x = self.conv3(x) \n",
    "        # print(\"After conv3:\", x.shape)\n",
    "        x = x.view(x.size(0), -1)   # \n",
    "        # print(\"After view:\", x.shape)\n",
    "        output = self.output(x)     # 输出[50,10]\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # adjust model\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()   # 继承__init__功能\n",
    "#         ## 第一层卷积\n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             # 输入[1,200,60]\n",
    "#             nn.Conv2d(\n",
    "#                 in_channels=1,    # 输入图片的高度\n",
    "#                 out_channels=32,  # 输出图片的高度\n",
    "#                 kernel_size=(20,3),    # 20x3的卷积核，相当于过滤器\n",
    "#                 stride=1,         # 卷积核在图上滑动，每隔一个扫一次\n",
    "#                 padding=2,        # 给图外边补上0\n",
    "#             ),\n",
    "#             # 经过卷积层 输出[32,200,60] 传入池化层\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=(10,1))   # 经过池化 输出[32,20,60] 传入下一个卷积\n",
    "#         )\n",
    "#         ## 第二层卷积\n",
    "#         self.conv2 = nn.Sequential(\n",
    "#             nn.Conv2d(\n",
    "#                 in_channels=32,    # 同上\n",
    "#                 out_channels=64,\n",
    "#                 kernel_size=(3,3),\n",
    "#                 stride=1,\n",
    "#                 padding=1\n",
    "#             ),\n",
    "#             # 经过卷积 输出[64, 40, 30] 传入池化层\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=(3,2))  # 经过池化 输出[64,7,30] 传入下一个卷积\n",
    "#         )\n",
    "#         ## 第三层卷积\n",
    "#         self.conv3 = nn.Sequential(\n",
    "#             nn.Conv2d(\n",
    "#                 in_channels=64,    # 同上\n",
    "#                 out_channels=128,\n",
    "#                 kernel_size=(3,3),\n",
    "#                 stride=1,\n",
    "#                 padding=2\n",
    "#             ),\n",
    "#             # 经过卷积 输出[128, 6, 30] 传入池化层\n",
    "#             ####### 这几个的 size 计算有点迷，得看加了 padding 之后对池化的影响\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2)  # 经过池化 输出[128,4,17] 传入下一个卷积\n",
    "#         )\n",
    "#         # # \n",
    "#         # self.conv4 = nn.Sequential(\n",
    "#         #     nn.Conv2d(256,512,kernel_size=(3,3),stride=1,padding=1),\n",
    "#         #     nn.ReLU(),\n",
    "#         #     nn.MaxPool2d(kernel_size=(2,1))\n",
    "#         # )\n",
    "#         # Dropout层，减少过拟合\n",
    "#         self.fc1 = nn.Sequential(\n",
    "#             nn.Linear(128*4*4,1024), # 根据输入尺寸计算\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(p=0.5), # 50%的Dropout概率\n",
    "#             nn.Linear(1024,49)\n",
    "#         )\n",
    "#         ## 输出层 \n",
    "#         ######### in_features 只要对齐就行了，看编译器要多少就改成多少\n",
    "#         # self.output = nn.Linear(in_features=128*10*4, out_features=49)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.tensor(x)\n",
    "#         x = x.to(torch.float32)\n",
    "#         x = x.cuda()\n",
    "#         x = self.conv1(x)\n",
    "#         # print(\"After conv1:\", x.shape)\n",
    "#         x = self.conv2(x)           #\n",
    "#         # print(\"After conv2:\", x.shape)\n",
    "#         x = self.conv3(x) \n",
    "#         # print(\"After conv3:\", x.shape)\n",
    "#         # x = self.conv4(x)\n",
    "#         # print(\"After conv4:\", x.shape)\n",
    "#         x = x.view(x.size(0), -1)   \n",
    "#         # print(\"After view:\", x.shape)\n",
    "#         output = self.fc1(x)\n",
    "#         # print(\"After fc1:\", x.shape)\n",
    "#         # output = self.output(x)     # 输出[50,10]\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn 实例化\n",
    "# CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "cnn = CNN()\n",
    "print(cnn)\n",
    "#初始化TensorBoard\n",
    "# writer = SummaryWriter(log_dir='runs/experiment1')\n",
    "\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# 如果GPU可用，将模型迁移至GPU\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "if torch.cuda.is_available():\n",
    "    cnn = cnn.cuda()\n",
    "\n",
    "\n",
    "epoches = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate,weight_decay=0.005)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "if torch.cuda.is_available():\n",
    "    loss_function = loss_function.cuda()\n",
    "\n",
    "# 开始训练\n",
    "for epoch in range(epoches):\n",
    "    print(\"进行第{}个epoch\".format(epoch))\n",
    "    for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        batch_x = batch_x.cuda()\n",
    "        batch_y = batch_y.cuda()\n",
    "        \n",
    "        output = cnn(batch_x)  # batch_x=[64,1,200,60]\n",
    "\n",
    "        loss = loss_function(output, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 每一步记录训练损失到TensorBoard\n",
    "        # writer.add_scalar('Loss/train',loss.item(),epoch* len(train_loader)+step)\n",
    "        \n",
    "        # 为了实时显示准确率\n",
    "        if step % 64 == 0:\n",
    "            with torch.no_grad():\n",
    "                test_output = cnn(X_test).cpu()\n",
    "                pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "                accuracy = float(np.sum(pred_y == Y_test)) / float(Y_test.shape[0])\n",
    "                print('Epoch: ', epoch, '| train loss: %.4f' % loss.cpu().data.numpy(), '| test accuracy: %.2f' % accuracy)\n",
    "            \n",
    "            # 记录测试准确率到TensorBoard\n",
    "            # writer.add_scalar('Accuracy/test',accuracy,epoch*len(train_loader)+step)\n",
    "        \n",
    "        # 保存训练损失和测试准确率\n",
    "        train_losses.append(loss.cpu().data.numpy())\n",
    "        test_accuracies.append(accuracy)\n",
    "    torch.cuda.empty_cache()\n",
    "    del batch_x,batch_y,output,loss\n",
    "    gc.collect()\n",
    "# writer.close()\n",
    "\n",
    "test_output = cnn(X_test[:10]).cpu()\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "print(pred_y)\n",
    "print(X_test[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制结果\n",
    "#保存训练损失和测试准确率图表\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses,label='Train Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss over Iterations')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(test_accuracies,label='Test Accuracy')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Test Accuracy over Iterations')\n",
    "plt.savefig(os.path.join(current_dir,'runs/experiment1/',filename+'.png'))\n",
    "# plt.savefig(os.path.join(current_dir,'runs/experiment1/','emg_100_12'+'.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"max_test_accuracy:{:.2f}%\".format(max(test_accuracies)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 model 是你的 CNN 模型\n",
    "torch.save(cnn.state_dict(), 'model/weight/'+filename+'.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
